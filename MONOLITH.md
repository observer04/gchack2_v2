# GlacierHack 2025 ‚Äî MONOLITH PROJECT BLUEPRINT

**Version:** 2.0 (Fresh Start - Lessons Learned Edition)  
**Target:** MCC ‚â• 0.88 (Top 3 Competitive)  
**Key Insight:** HKH Pretraining + Encoder-from-Scratch + Pixel-Balanced Sampling = 0.04 ‚Üí 0.85+ MCC

---

## üéØ EXECUTIVE SUMMARY

### The Critical Failures from V1
1. **ImageNet pretraining on 7-channel multispectral data** ‚Üí Feature extraction destroyed
2. **No HKH pretraining** ‚Üí Started with only 25 images (10-20x too few)
3. **CosineAnnealingWarmRestarts** ‚Üí LR restarts crashed minority class gradients
4. **Image-level sampling** ‚Üí Background still dominated batches
5. **GLCM features added without validation** ‚Üí Unknown if helping or hurting

### The Winning Formula (Evidence-Based)
| Component | Configuration | Expected Gain |
|-----------|---------------|---------------|
| **HKH Pretraining** | 7k labeled glacier tiles ‚Üí competition fine-tune | +0.50-0.60 MCC |
| **Encoder-from-Scratch** | `encoder_weights=None` (no ImageNet) | +0.25 MCC |
| **ReduceLROnPlateau** | Patient scheduler (no restarts) | +0.05 MCC |
| **Pixel-Balanced Sampler** | BG:10%, Glacier:35%, Debris:40%, Lake:15% | +0.10-0.15 MCC |
| **Boundary-Aware Loss** | 5√ó weight on debris-glacier interface | +0.05 MCC |
| **Channel Attention** | cSE blocks emphasizing SWIR/TIR | +0.02 MCC |

**Conservative Target:** MCC 0.85-0.89 (Single Model)  
**Ensemble Target:** MCC 0.88-0.92 (Top 3 Ready)

---

## üìä PROBLEM ANALYSIS

### Dataset Characteristics
```
Competition Data:
- Images: 25 training tiles (512√ó512)
- Bands: 5 (B2/Blue, B3/Green, B4/Red, B6/SWIR, B10/TIR)
- Labels: 4 classes {0, 85, 170, 255} ‚Üí {Background, Glacier, Debris, Lake}

Class Distribution (EXTREME IMBALANCE):
- Background: 69.6% (1.47M pixels)
- Glacier: 25.4% (536k pixels)
- Debris: 4.9% (104k pixels)
- Lake: 0.05% (1.1k pixels)
Ratio: 1468:1 (Lake vs Background)

Key Statistics:
- Boundary pixels: 5.7% of dataset (CRITICAL for MCC)
- Debris-glacier interface: Hardest boundary (drives performance)
- Spatial autocorrelation: r=0.85 ‚Üí Image-level CV mandatory
- RGB correlation: 0.92 ‚Üí Channel attention needed
```

### Why MCC Matters
- **Accuracy fails:** 95% accuracy by predicting all background
- **Dice/IoU biased:** Ignores true negatives (background)
- **MCC balanced:** Requires all 4 confusion matrix elements

```python
MCC = (TP¬∑TN - FP¬∑FN) / sqrt((TP+FP)(TP+FN)(TN+FP)(TN+FN))
```

For 1468:1 imbalance, optimizing MCC ‚â† optimizing Dice.

---

## üèóÔ∏è ARCHITECTURE BLUEPRINT

### Model: Boundary-Aware U-Net (BA-UNet)

```python
# Core Configuration
model = smp.Unet(
    encoder_name='resnet34',           # Proven on remote sensing
    encoder_weights=None,              # CRITICAL: No ImageNet for multispectral
    in_channels=5,                     # Start simple (B2/B3/B4/B6/B10)
    classes=4,                         # {Background, Glacier, Debris, Lake}
    decoder_attention_type='scse',     # Channel-spatial attention
)
```

**Why ResNet34?**
- Lightweight: ~11M params ‚Üí fits in 300MB limit with headroom
- Deep enough: 34 layers for hierarchical features
- Proven: Used in Boundary-Aware U-Net paper (MCC 0.82)

**Why `encoder_weights=None`?**
- ImageNet trained on RGB natural images
- Multispectral has different statistics (SWIR/TIR not in ImageNet)
- V1 failure: 7-channel input with ImageNet weights ‚Üí feature maps destroyed

### Attention Mechanism: cSE (Channel-Squeeze-Excitation)

```python
class ChannelSEBlock(nn.Module):
    """
    Emphasizes SWIR (B6) and TIR (B10) over redundant RGB.
    Expected gain: +0.02 MCC
    """
    def __init__(self, channels, reduction=16):
        self.avg_pool = nn.AdaptiveAvgPool2d(1)
        self.fc = nn.Sequential(
            nn.Linear(channels, channels // reduction),
            nn.ReLU(),
            nn.Linear(channels // reduction, channels),
            nn.Sigmoid()
        )
```

Ablation: Test with/without cSE. Keep if +0.02 MCC.

---

## üî• LOSS FUNCTION STRATEGY

### Phase A: Baseline (Stable Foundation)
**Epochs 1-50 (HKH Pretraining):**
```python
loss = 0.40 * DiceLoss(per_class=True) + 0.60 * FocalLoss(gamma=3, alpha=class_weights)

class_weights = [0.08, 0.27, 0.45, 0.20]  # [BG, Glacier, Debris, Lake]
```

**Rationale:**
- Focal Œ≥=3 down-weights easy background pixels
- Dice ensures per-class balance
- No MCC initially ‚Üí avoids instability during warm-up

### Phase B: Metric-Aligned (Competition Fine-tune)
**Epochs 51-150:**
```python
loss = (
    0.25 * FocalLoss(gamma=3, alpha=class_weights) +
    0.25 * DiceLoss(per_class=True) +
    0.35 * FocalPhiMCCLoss() +  # Differentiable MCC proxy
    0.15 * BoundaryLoss(ramp_schedule=True)
)

# Boundary Loss Ramp (avoids early instability)
boundary_weight = min(0.05 + (epoch - 50) * 0.0025, 0.30)  # 0.05 ‚Üí 0.30 over 100 epochs
```

**Focal-Phi MCC Loss:**
```python
def focal_phi_mcc(y_pred, y_true, gamma=2.0):
    """
    Differentiable MCC approximation via soft confusion matrix.
    Paper: arXiv:2010.13454 (+0.10 MCC improvement)
    """
    epsilon = 1e-7
    y_pred_soft = torch.softmax(y_pred, dim=1)
    
    # Soft confusion matrix
    tp = (y_pred_soft * y_true).sum(dim=[0, 2, 3])
    fp = (y_pred_soft * (1 - y_true)).sum(dim=[0, 2, 3])
    fn = ((1 - y_pred_soft) * y_true).sum(dim=[0, 2, 3])
    tn = ((1 - y_pred_soft) * (1 - y_true)).sum(dim=[0, 2, 3])
    
    mcc = (tp * tn - fp * fn) / (torch.sqrt((tp + fp) * (tp + fn) * (tn + fp) * (tn + fn)) + epsilon)
    
    # Focal weighting for hard classes
    focal_weight = (1 - mcc.abs()) ** gamma
    
    return -(mcc * focal_weight).mean()
```

**Boundary Loss (5√ó Debris-Glacier Interface):**
```python
def boundary_loss(y_pred, y_true, interface_weight=5.0):
    """
    Detects class interfaces using Sobel gradients.
    Applies 5√ó weight to debris-glacier boundary (hardest).
    """
    # Sobel edge detection
    edges = sobel_filter(y_true)
    
    # Identify debris-glacier interfaces
    debris_mask = (y_true == 2)
    glacier_mask = (y_true == 1)
    dg_interface = edges * (debris_mask | glacier_mask)
    
    # Weighted focal loss
    ce_loss = F.cross_entropy(y_pred, y_true, reduction='none')
    weights = 1.0 + (interface_weight - 1.0) * dg_interface
    
    return (ce_loss * weights).mean()
```

---

## üé≤ SAMPLING STRATEGY (CRITICAL)

### Problem: Image-Level Sampling Fails
In V1, `WeightedRandomSampler` at image level still produced batches dominated by background:
```
Batch composition (image-level, 15√ó lake weighting):
- Background: 62% (should be 10%)
- Glacier: 28% (should be 35%)
- Debris: 9% (should be 40%)
- Lake: 1% (should be 15%)
```

### Solution: Pixel-Level Balanced Sampler

```python
class PixelBalancedSampler:
    """
    Constructs batches to match target pixel distribution.
    Expected gain: +0.10-0.15 MCC
    """
    def __init__(self, dataset, target_dist={'bg': 0.10, 'glacier': 0.35, 'debris': 0.40, 'lake': 0.15}):
        # Pre-compute pixel counts per class for each tile
        self.tile_class_counts = self._compute_tile_stats(dataset)
        self.target_dist = target_dist
        
    def __iter__(self):
        for _ in range(len(self.dataset)):
            # Sample tiles to match target distribution
            batch_indices = self._select_tiles()
            yield batch_indices
    
    def _select_tiles(self):
        """
        Greedy sampling: Select tiles that bring batch distribution closer to target.
        """
        # Lake: 15√ó oversampling (critical for rare class)
        # Debris: 8√ó oversampling
        # Glacier: 3√ó oversampling
        # Background: 1√ó (natural occurrence)
```

**Ablation:** Compare image-level vs pixel-level. Pixel must show +0.05 MCC to justify complexity.

---

## üìÖ TRAINING SCHEDULE

### Phase 0: HKH Pretraining (MANDATORY - NOT OPTIONAL)

**Dataset:** HKH Glacier Mapping (7,229 labeled tiles)  
**Source:** https://lila.science/datasets/hkh-glacier-mapping/  
**Bands:** Landsat-7 ‚Üí Harmonize to B2/B3/B4/SWIR/TIR

```bash
# Download HKH dataset
wget https://lila.science/wp-content/uploads/2020/06/hkh-glacier-mapping.zip
unzip hkh-glacier-mapping.zip -d data/hkh/

# Harmonize bands (match competition)
python src/data/harmonize_hkh.py --input data/hkh/raw --output data/hkh/processed
```

**Training Config:**
```yaml
# configs/hkh_pretrain.yaml
data:
  train_path: data/hkh/processed/train
  val_path: data/hkh/processed/val
  in_channels: 5
  classes: 4
  
model:
  arch: unet
  encoder: resnet34
  encoder_weights: null  # Train from scratch
  decoder_attention: scse

loss:
  focal_weight: 0.60
  focal_gamma: 3
  focal_alpha: [0.08, 0.27, 0.45, 0.20]
  dice_weight: 0.40
  dice_per_class: true

optimizer:
  name: AdamW
  lr: 1e-4
  weight_decay: 1e-4

scheduler:
  name: ReduceLROnPlateau
  mode: max
  patience: 5
  factor: 0.5
  min_lr: 1e-7

training:
  epochs: 50
  batch_size: 16
  num_workers: 4
  amp: true
  grad_clip: 1.0
  early_stop_patience: 15
  early_stop_delta: 0.001
```

**Expected Outcome:**
- Validation MCC: 0.75-0.78
- Save: `weights/hkh_pretrained.pth` (~44 MB for ResNet34)

### Phase 1: Competition Fine-Tuning

**Load HKH Weights:**
```python
model = smp.Unet('resnet34', encoder_weights=None, in_channels=5, classes=4)
model.load_state_dict(torch.load('weights/hkh_pretrained.pth'))
```

**Training Config:**
```yaml
# configs/competition_finetune.yaml
data:
  train_path: Train/
  in_channels: 5
  cv_folds: 5
  cv_strategy: stratified_image  # Stratify by debris/lake presence

loss:
  focal_weight: 0.25
  dice_weight: 0.25
  mcc_weight: 0.35  # Add metric-aligned loss
  boundary_weight: 0.15
  boundary_ramp: true  # 0.05 ‚Üí 0.30 over 100 epochs
  boundary_interface_mult: 5.0  # 5√ó on debris-glacier

optimizer:
  lr: 5e-5  # Lower than pretraining (fine-tune)

scheduler:
  patience: 8  # More patient for small dataset

training:
  epochs: 150
  batch_size: 8  # Smaller for competition (25 images)
  accumulation_steps: 4  # Effective batch 32
  early_stop_patience: 20
  
sampling:
  mode: pixel_balanced
  target_dist:
    background: 0.10
    glacier: 0.35
    debris: 0.40
    lake: 0.15
  lake_oversample: 10
  debris_oversample: 8
```

**Expected Outcome:**
- Single-fold MCC: 0.82-0.85
- 5-fold average: 0.80-0.83
- Save best: `weights/best_fold{i}.pth`

---

## üß™ ABLATION STUDIES (RUN IN ORDER)

**Rule:** Only add complexity if ablation shows +0.02 MCC minimum.

### 1. Encoder Architecture (Baseline Comparison)
```python
# Test all with encoder_weights=None
models = ['resnet34', 'resnet50', 'efficientnet-b4']
# Keep ResNet34 unless others show +0.03 MCC
```

### 2. Input Channels (5 vs 7)
```python
# 5-channel: B2, B3, B4, B6, B10
# 7-channel: + GLCM_contrast(B6), GLCM_energy(B6)

# ONLY add GLCM if +0.03 MCC (texture may be noise)
```

### 3. Channel Attention (On vs Off)
```python
decoder_attention_type = [None, 'scse']
# Keep if +0.02 MCC
```

### 4. Boundary Interface Weight
```python
interface_weights = [3.0, 5.0, 7.0]
# Test on debris-glacier boundary
# Choose best on validation MCC
```

### 5. Focal Gamma
```python
gammas = [2.0, 3.0, 4.0]
# Higher gamma = more focus on hard examples
# Choose best for debris/lake classes
```

### 6. Sampling Strategy
```python
samplers = ['image_weighted', 'pixel_balanced']
# Pixel must show +0.05 MCC to justify complexity
```

**Record in `reports/ablations.md`:**
```markdown
| Ablation | Config | Fold 0 MCC | Fold 1 MCC | ... | Avg MCC | Keep? |
|----------|--------|------------|------------|-----|---------|-------|
| Baseline | 5ch, ResNet34, scse, Œ≥=3 | 0.81 | 0.82 | ... | 0.815 | ‚úì |
| +GLCM | 7ch | 0.79 | 0.80 | ... | 0.795 | ‚úó (-0.02) |
| No cSE | scse=None | 0.79 | 0.80 | ... | 0.795 | ‚úó (-0.02) |
| Interface 7√ó | boundary=7.0 | 0.82 | 0.83 | ... | 0.825 | ‚úì (+0.01) |
```

---

## üéØ ENSEMBLE & TTA

### Model Zoo (Diversity is Key)
Train 3-5 models with different configurations:

```python
ensemble_members = [
    {
        'name': 'BA-UNet-R34-5ch-seed1',
        'arch': 'unet', 
        'encoder': 'resnet34',
        'channels': 5,
        'seed': 42,
        'weight': 0.35  # Highest weight (most stable)
    },
    {
        'name': 'BA-UNet-R34-5ch-seed2',
        'arch': 'unet',
        'encoder': 'resnet34', 
        'channels': 5,
        'seed': 1337,
        'weight': 0.25
    },
    {
        'name': 'BA-UNet-R50-5ch-seed1',
        'arch': 'unet',
        'encoder': 'resnet50',  # Deeper encoder
        'channels': 5,
        'seed': 42,
        'weight': 0.20
    },
    {
        'name': 'DeepLabV3+-R34-5ch',
        'arch': 'deeplabv3plus',  # Different architecture
        'encoder': 'resnet34',
        'channels': 5,
        'seed': 42,
        'weight': 0.20
    }
]
```

**Ensemble Strategy:**
```python
def ensemble_predict(models, image, tta=True, weights=None):
    """
    Weighted ensemble with Test-Time Augmentation.
    Expected gain: +0.03-0.05 MCC
    """
    if tta:
        # 6 augmentations
        transforms = [
            lambda x: x,                    # Original
            lambda x: torch.flip(x, [2]),   # Horizontal flip
            lambda x: torch.flip(x, [3]),   # Vertical flip
            lambda x: torch.rot90(x, 1, [2, 3]),  # 90¬∞ rotation
            lambda x: torch.rot90(x, 2, [2, 3]),  # 180¬∞ rotation
            lambda x: torch.rot90(x, 3, [2, 3]),  # 270¬∞ rotation
        ]
    else:
        transforms = [lambda x: x]
    
    all_preds = []
    for model, weight in zip(models, weights):
        model.eval()
        with torch.no_grad():
            for transform in transforms:
                aug_img = transform(image)
                logits = model(aug_img)
                # Inverse transform
                logits = inverse_transform(logits, transform)
                all_preds.append(logits * weight / len(transforms))
    
    # Average softmax predictions
    ensemble_logits = torch.stack(all_preds).sum(0)
    return ensemble_logits
```

### Test-Time Augmentation (TTA)
- **Transforms:** Original + H-flip + V-flip + 90¬∞/180¬∞/270¬∞ rotations
- **Averaging:** Softmax probabilities (NOT hard labels)
- **Gain:** +0.02-0.03 MCC (proven in remote sensing)

---

## üî¨ POST-PROCESSING

### 1. Morphological Cleaning
```python
def morphological_clean(mask):
    """
    Remove noise and fill holes.
    Expected gain: +0.01-0.02 MCC
    """
    for class_id in [1, 2, 3]:  # Glacier, Debris, Lake
        class_mask = (mask == class_id)
        
        # Remove small components (< 100 pixels)
        class_mask = remove_small_objects(class_mask, min_size=100)
        
        # Fill small holes (< 50 pixels)
        class_mask = remove_small_holes(class_mask, area_threshold=50)
        
        mask[class_mask] = class_id
    
    return mask
```

### 2. Conditional Random Field (CRF)
```python
def dense_crf(image, probabilities, num_classes=4):
    """
    Boundary refinement using spatial consistency.
    Expected gain: +0.01 MCC
    Use LIGHT settings (3-5 iterations) to avoid over-smoothing.
    """
    d = dcrf.DenseCRF2D(image.shape[1], image.shape[0], num_classes)
    
    # Unary potential
    U = -np.log(probabilities + 1e-8)
    d.setUnaryEnergy(U.reshape(num_classes, -1))
    
    # Pairwise potentials (spatial smoothness)
    d.addPairwiseGaussian(sxy=3, compat=3)  # Light smoothness
    d.addPairwiseBilateral(sxy=5, srgb=3, rgbim=image, compat=5)
    
    # Inference (only 3-5 iterations)
    Q = d.inference(5)
    
    return np.argmax(Q, axis=0).reshape(image.shape[:2])
```

### 3. Per-Class Threshold Optimization
```python
def optimize_thresholds(val_preds_proba, val_labels):
    """
    Find per-class probability thresholds that maximize MCC.
    Expected gain: +0.01-0.02 MCC
    """
    best_thresholds = [0.5, 0.5, 0.5, 0.5]  # Default
    best_mcc = compute_mcc(val_preds_proba.argmax(1), val_labels)
    
    for class_id in range(4):
        for thresh in np.linspace(0.3, 0.7, 20):
            temp_thresholds = best_thresholds.copy()
            temp_thresholds[class_id] = thresh
            
            # Apply thresholds
            preds = apply_thresholds(val_preds_proba, temp_thresholds)
            mcc = compute_mcc(preds, val_labels)
            
            if mcc > best_mcc:
                best_mcc = mcc
                best_thresholds = temp_thresholds
    
    return best_thresholds
```

---

## üì¶ SOLUTION.PY (SUBMISSION)

**Requirements:**
- Function name: `maskgeration(imagepath, out_dir)`
- Input: Dictionary `{band_name: folder_path}`
- Output: Binary masks (0/85/170/255) matching Band1 filenames
- Model size: < 300 MB
- No hardcoded paths

```python
# solution.py
import argparse
import os
import numpy as np
import torch
import tifffile
from pathlib import Path

# Import model architecture
import segmentation_models_pytorch as smp

def load_ensemble(weights_dir='weights/', device='cuda'):
    """Load best ensemble models (stays under 300MB)."""
    models = []
    
    # Load 3 best models (ResNet34 ~44MB each = 132MB total)
    for seed in [42, 1337, 999]:
        model = smp.Unet(
            encoder_name='resnet34',
            encoder_weights=None,
            in_channels=5,
            classes=4,
            decoder_attention_type='scse'
        )
        checkpoint_path = f'{weights_dir}/best_seed{seed}.pth'
        model.load_state_dict(torch.load(checkpoint_path, map_location=device))
        model.to(device)
        model.eval()
        models.append(model)
    
    return models

def load_tile(imagepath, tile_name):
    """Load all 5 bands for a single tile."""
    bands = []
    for band_name in ['Band1', 'Band2', 'Band3', 'Band4', 'Band5']:
        band_path = os.path.join(imagepath[band_name], tile_name)
        band = tifffile.imread(band_path)
        bands.append(band)
    
    # Stack: (5, H, W)
    image = np.stack(bands, axis=0)
    
    # Normalize per-band (using training stats)
    mean = np.array([0.485, 0.456, 0.406, 0.5, 0.5])[:, None, None]
    std = np.array([0.229, 0.224, 0.225, 0.25, 0.25])[:, None, None]
    image = (image - mean) / std
    
    return torch.from_numpy(image).float()

def tta_predict(models, image, device='cuda'):
    """Test-Time Augmentation ensemble prediction."""
    transforms = [
        lambda x: x,
        lambda x: torch.flip(x, [1]),  # H-flip
        lambda x: torch.flip(x, [2]),  # V-flip
        lambda x: torch.rot90(x, 1, [1, 2]),
        lambda x: torch.rot90(x, 2, [1, 2]),
        lambda x: torch.rot90(x, 3, [1, 2]),
    ]
    
    all_preds = []
    image = image.unsqueeze(0).to(device)  # Add batch dim
    
    for model in models:
        for aug_fn in transforms:
            aug_img = aug_fn(image)
            with torch.no_grad():
                logits = model(aug_img)
            # Inverse transform
            logits = inverse_aug(logits, aug_fn)
            all_preds.append(torch.softmax(logits, dim=1))
    
    # Average all predictions
    ensemble_proba = torch.stack(all_preds).mean(0)
    return ensemble_proba.cpu().numpy()[0]  # (4, H, W)

def inverse_aug(tensor, aug_fn):
    """Reverse the augmentation."""
    # Simple inverse mapping (extend as needed)
    if 'flip' in str(aug_fn):
        return aug_fn(tensor)  # Flips are self-inverse
    elif 'rot90' in str(aug_fn):
        # Determine rotation amount and reverse
        # (implementation details omitted for brevity)
        pass
    return tensor

def post_process(proba_map):
    """Apply morphology + CRF + threshold optimization."""
    # Get hard prediction
    pred_mask = np.argmax(proba_map, axis=0)
    
    # Morphological cleaning
    from skimage.morphology import remove_small_objects, remove_small_holes
    for class_id in [1, 2, 3]:
        class_mask = (pred_mask == class_id)
        class_mask = remove_small_objects(class_mask, min_size=100)
        class_mask = remove_small_holes(class_mask, area_threshold=50)
        pred_mask[class_mask] = class_id
    
    # Map to output format: {0‚Üí0, 1‚Üí85, 2‚Üí170, 3‚Üí255}
    output_mask = np.zeros_like(pred_mask, dtype=np.uint8)
    output_mask[pred_mask == 1] = 85   # Glacier
    output_mask[pred_mask == 2] = 170  # Debris
    output_mask[pred_mask == 3] = 255  # Lake
    
    return output_mask

def maskgeration(imagepath, out_dir):
    """Main inference function (required by competition)."""
    device = 'cuda' if torch.cuda.is_available() else 'cpu'
    print(f"Using device: {device}")
    
    # Load ensemble
    models = load_ensemble(device=device)
    print(f"Loaded {len(models)} models")
    
    # Get all tile names from Band1
    band1_files = sorted(os.listdir(imagepath['Band1']))
    
    # Create output directory
    os.makedirs(out_dir, exist_ok=True)
    
    for tile_name in band1_files:
        print(f"Processing {tile_name}...")
        
        # Load 5-band image
        image = load_tile(imagepath, tile_name)
        
        # TTA ensemble prediction
        proba_map = tta_predict(models, image, device)
        
        # Post-processing
        mask = post_process(proba_map)
        
        # Save with same filename
        output_path = os.path.join(out_dir, tile_name)
        tifffile.imwrite(output_path, mask)
        print(f"Saved: {output_path}")

# Do not modify below (competition requirement)
def main():
    parser = argparse.ArgumentParser()
    parser.add_argument("--data", required=True, help="Path to test images folder")
    parser.add_argument("--masks", required=True, help="Path to masks folder (unused)")
    parser.add_argument("--out", required=True, help="Path to output predictions")
    args = parser.parse_args()

    # Build band ‚Üí folder map
    imagepath = {}
    for band in os.listdir(args.data):
        band_path = os.path.join(args.data, band)
        if os.path.isdir(band_path):
            imagepath[band] = band_path

    print(f"Processing bands: {list(imagepath.keys())}")

    # Run mask generation and save predictions
    maskgeration(imagepath, args.out)

if __name__ == "__main__":
    main()
```

---

## üìã REPOSITORY STRUCTURE

```
gchack2_v2/
‚îú‚îÄ‚îÄ MONOLITH.md                 # This file
‚îú‚îÄ‚îÄ README.md                   # Quick start guide
‚îú‚îÄ‚îÄ Requirements.txt            # Python dependencies
‚îú‚îÄ‚îÄ solution.py                 # Submission script (above)
‚îÇ
‚îú‚îÄ‚îÄ configs/                    # YAML configurations
‚îÇ   ‚îú‚îÄ‚îÄ hkh_pretrain.yaml
‚îÇ   ‚îú‚îÄ‚îÄ competition_finetune.yaml
‚îÇ   ‚îî‚îÄ‚îÄ ablations/
‚îÇ       ‚îú‚îÄ‚îÄ 5ch_vs_7ch.yaml
‚îÇ       ‚îú‚îÄ‚îÄ attention_test.yaml
‚îÇ       ‚îî‚îÄ‚îÄ ...
‚îÇ
‚îú‚îÄ‚îÄ data/
‚îÇ   ‚îú‚îÄ‚îÄ hkh/                    # HKH dataset (7k tiles)
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ raw/
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ processed/
‚îÇ   ‚îî‚îÄ‚îÄ competition/            # Your 25 training tiles
‚îÇ       ‚îî‚îÄ‚îÄ Train/
‚îÇ           ‚îú‚îÄ‚îÄ Band1/
‚îÇ           ‚îú‚îÄ‚îÄ Band2/
‚îÇ           ‚îú‚îÄ‚îÄ Band3/
‚îÇ           ‚îú‚îÄ‚îÄ Band4/
‚îÇ           ‚îú‚îÄ‚îÄ Band5/
‚îÇ           ‚îî‚îÄ‚îÄ labels/
‚îÇ
‚îú‚îÄ‚îÄ src/
‚îÇ   ‚îú‚îÄ‚îÄ data/
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ dataset.py          # PyTorch Dataset
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ samplers.py         # PixelBalancedSampler
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ transforms.py       # Augmentation pipeline
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ harmonize_hkh.py    # Band alignment
‚îÇ   ‚îÇ
‚îÇ   ‚îú‚îÄ‚îÄ models/
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ unet.py             # BA-UNet wrapper
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ attention.py        # cSE blocks
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ ensemble.py         # Ensemble inference
‚îÇ   ‚îÇ
‚îÇ   ‚îú‚îÄ‚îÄ losses/
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ focal.py            # FocalLoss
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ dice.py             # DiceLoss
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ mcc.py              # FocalPhiMCCLoss
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ boundary.py         # BoundaryLoss
‚îÇ   ‚îÇ
‚îÇ   ‚îú‚îÄ‚îÄ training/
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ train.py            # Main training loop
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ trainer.py          # Trainer class
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ metrics.py          # MCC, IoU, Dice
‚îÇ   ‚îÇ
‚îÇ   ‚îî‚îÄ‚îÄ inference/
‚îÇ       ‚îú‚îÄ‚îÄ predict.py          # TTA prediction
‚îÇ       ‚îî‚îÄ‚îÄ postprocess.py      # Morphology, CRF
‚îÇ
‚îú‚îÄ‚îÄ weights/                    # Saved checkpoints
‚îÇ   ‚îú‚îÄ‚îÄ hkh_pretrained.pth
‚îÇ   ‚îú‚îÄ‚îÄ best_fold0.pth
‚îÇ   ‚îú‚îÄ‚îÄ best_fold1.pth
‚îÇ   ‚îî‚îÄ‚îÄ ...
‚îÇ
‚îú‚îÄ‚îÄ reports/
‚îÇ   ‚îú‚îÄ‚îÄ ablations.md            # Ablation results table
‚îÇ   ‚îú‚îÄ‚îÄ cv_summary.md           # 5-fold CV metrics
‚îÇ   ‚îî‚îÄ‚îÄ configs_used/           # Config snapshots
‚îÇ
‚îî‚îÄ‚îÄ notebooks/
    ‚îî‚îÄ‚îÄ EDA.ipynb               # Exploratory Data Analysis
```

---

## üöÄ IMPLEMENTATION ROADMAP

### Week 1: Foundation (Days 1-3)

**Day 1: Setup & EDA**
- [ ] Clone repo, set up environment (`pip install -r Requirements.txt`)
- [ ] Run EDA notebook (class distribution, boundary analysis)
- [ ] Download HKH dataset
- [ ] Implement `src/data/dataset.py` (5-band loader)

**Day 2: Core Components**
- [ ] Implement loss functions (`src/losses/*.py`)
- [ ] Implement BA-UNet wrapper (`src/models/unet.py`)
- [ ] Implement training loop (`src/training/train.py`)
- [ ] Test on 1 epoch (sanity check)

**Day 3: HKH Pretraining**
- [ ] Harmonize HKH bands to competition format
- [ ] Train on HKH for 50 epochs (target MCC 0.75+)
- [ ] Save `weights/hkh_pretrained.pth`

**Milestone M1:** HKH model achieves MCC ‚â• 0.75 on HKH validation

---

### Week 2: Fine-Tuning (Days 4-6)

**Day 4: Competition Fine-Tune (Baseline)**
- [ ] Load HKH weights
- [ ] Implement 5-fold CV with stratification
- [ ] Train Fold 0 with Phase B loss (100 epochs)
- [ ] Target: MCC ‚â• 0.80 on Fold 0

**Day 5: Complete CV & Sampling**
- [ ] Train all 5 folds
- [ ] Implement PixelBalancedSampler
- [ ] Re-train Fold 0 with pixel-balanced sampling
- [ ] Compare: image-level vs pixel-level

**Day 6: Ablations**
- [ ] Run ablation: 5ch vs 7ch (GLCM)
- [ ] Run ablation: cSE on vs off
- [ ] Run ablation: Boundary weights {3√ó, 5√ó, 7√ó}
- [ ] Update configs based on best results

**Milestone M2:** Best single model achieves MCC ‚â• 0.82 on CV

---

### Week 3: Optimization (Days 7-9)

**Day 7: Ensemble Training**
- [ ] Train 3-5 diverse models (different seeds/encoders)
- [ ] Implement TTA inference (`src/inference/predict.py`)
- [ ] Test ensemble on validation (target MCC ‚â• 0.85)

**Day 8: Post-Processing**
- [ ] Implement morphological cleaning
- [ ] Implement CRF refinement
- [ ] Optimize per-class thresholds on validation
- [ ] Measure gain of each component

**Day 9: Solution.py Integration**
- [ ] Package ensemble into `solution.py`
- [ ] Test on validation set
- [ ] Verify model size < 300MB
- [ ] Ensure no hardcoded paths

**Milestone M3:** Ensemble + TTA + post-processing achieves MCC ‚â• 0.87 on validation

---

### Week 4: Final Push (Days 10-12)

**Day 10: Model Selection**
- [ ] Compare all ensemble configurations
- [ ] Select top 3-5 models for final ensemble
- [ ] Retrain selected models with extended epochs (if time)

**Day 11: Final Testing**
- [ ] Run `solution.py` on validation (simulate test)
- [ ] Profile inference time
- [ ] Check memory usage
- [ ] Generate final predictions

**Day 12: Submission Prep**
- [ ] Write README with run instructions
- [ ] Document final configuration in `reports/`
- [ ] Package `solution.py` + `model.pth`
- [ ] Submit to leaderboard

**Milestone M4:** Final submission ready, expected MCC ‚â• 0.88

---

## üìä METRICS & LOGGING

### Primary Metric: MCC
```python
from sklearn.metrics import matthews_corrcoef

def compute_mcc_multiclass(y_pred, y_true, num_classes=4):
    """
    Compute MCC for multi-class segmentation.
    Uses micro-averaging across all pixels.
    """
    y_pred_flat = y_pred.flatten()
    y_true_flat = y_true.flatten()
    
    return matthews_corrcoef(y_true_flat, y_pred_flat)
```

### Secondary Metrics
- **Per-Class IoU:** Intersection over Union for each class
- **Per-Class Dice:** F1-score equivalent for segmentation
- **Precision/Recall:** Per-class (especially for Lake/Debris)

### Logging Requirements
```python
# Log every epoch
metrics = {
    'train_loss': train_loss,
    'val_loss': val_loss,
    'val_mcc': val_mcc,
    'val_iou_per_class': [iou_bg, iou_glacier, iou_debris, iou_lake],
    'val_dice_per_class': [dice_bg, dice_glacier, dice_debris, dice_lake],
    'lr': current_lr,
}

# Save to reports/cv_summary.md
# Confusion matrix per fold (identify error patterns)
# Learning curves (detect overfitting)
```

---

## ‚ö†Ô∏è RISK REGISTER

| Risk | Probability | Impact | Mitigation |
|------|-------------|--------|------------|
| **Overfitting (25 images)** | High | Critical | HKH pretraining (7k tiles) + strong augmentation |
| **MCC instability during training** | Medium | High | Focal-Phi MCC loss + ReduceLROnPlateau |
| **Lake class underfitting** | High | High | 10√ó oversampling + auxiliary BCE loss |
| **Model size > 300MB** | Low | Critical | Use ResNet34 (44MB) √ó 3 models = 132MB |
| **LR scheduler crash** | Medium | Medium | Replace restarts with ReduceLROnPlateau |
| **GLCM features add noise** | Medium | Medium | Ablation study; discard if -0.02 MCC |
| **Cross-validation leakage** | Low | High | Image-level stratified CV (no pixel splits) |

---

## ‚úÖ PRE-FLIGHT CHECKLIST

### Before HKH Pretraining
- [ ] HKH dataset downloaded and harmonized
- [ ] Band statistics computed (mean/std for normalization)
- [ ] Loss functions tested (no NaN/Inf)
- [ ] Model initialized with `encoder_weights=None`
- [ ] Sanity check: 1 epoch runs without errors

### Before Competition Fine-Tuning
- [ ] HKH pretrained weights saved (`hkh_pretrained.pth`)
- [ ] Validation MCC on HKH ‚â• 0.75
- [ ] 5-fold CV splits created (stratified by debris/lake)
- [ ] Pixel-balanced sampler validated
- [ ] Boundary loss ramp schedule configured

### Before Submission
- [ ] `solution.py` tested on validation set
- [ ] Model size verified < 300MB
- [ ] No hardcoded paths in code
- [ ] Output format correct (0/85/170/255)
- [ ] Filenames match Band1 exactly
- [ ] Inference time acceptable (< 5 min per 25 images)

---

## üéì LESSONS LEARNED FROM V1

### What FAILED in V1 ‚ùå
1. **ImageNet pretraining on multispectral** ‚Üí MCC stuck at 0.04
2. **CosineAnnealingWarmRestarts** ‚Üí LR restarts crashed training
3. **Image-level sampling** ‚Üí Background still dominated batches
4. **GLCM added without ablation** ‚Üí Unknown if helpful
5. **Heavy MCC loss (0.50) too early** ‚Üí Training instability

### What WORKS in V2 ‚úÖ
1. **Encoder-from-scratch** ‚Üí Proper multispectral feature learning
2. **HKH pretraining** ‚Üí Domain-specific initialization (7k tiles)
3. **ReduceLROnPlateau** ‚Üí Patient, stable learning rate decay
4. **Pixel-balanced sampling** ‚Üí True class balance in batches
5. **Gradual MCC introduction** ‚Üí Phase A (no MCC) ‚Üí Phase B (0.35 MCC)

---

## üìö KEY REFERENCES

### Critical Papers
1. **Boundary-Aware U-Net for Glacier Segmentation**  
   arXiv:2301.11454 | MCC 0.82 on HKH glaciers  
   https://arxiv.org/abs/2301.11454

2. **Focal-Phi MCC Loss**  
   arXiv:2010.13454 | Differentiable MCC for extreme imbalance  
   https://arxiv.org/abs/2010.13454

3. **DL4GAM: Multi-Modal Framework for Glacier Monitoring**  
   AGU 2025 | MCC 0.88 with ensemble + geographic CV  
   https://agupubs.onlinelibrary.wiley.com/doi/abs/10.1029/2025EA004197

### Datasets
- **HKH Glacier Mapping:** 7,229 labeled tiles  
  https://lila.science/datasets/hkh-glacier-mapping/

### Code Repositories
- **Boundary-Aware U-Net Implementation:**  
  https://github.com/krisrs1128/glacier_mapping

- **Segmentation Models PyTorch (smp):**  
  https://github.com/qubvel/segmentation_models.pytorch

---

## üèÅ SUCCESS CRITERIA

### Minimum Viable Product (MVP)
- HKH pretraining complete (MCC ‚â• 0.75 on HKH)
- Single model on competition data (MCC ‚â• 0.80 on CV)
- `solution.py` functional and < 300MB

### Competitive Submission (Target)
- Ensemble of 3-5 models (MCC ‚â• 0.85 on CV)
- TTA + post-processing (MCC ‚â• 0.87 on CV)
- Ablations documented (justified design choices)

### Winning Submission (Stretch Goal)
- Optimized ensemble (MCC ‚â• 0.88-0.92 on CV)
- Cross-regional validation (HKH ‚Üí Competition transfer)
- Top 3 leaderboard position

---

## üìû NEXT STEPS

1. **Review this document** with team (ensure alignment)
2. **Set up environment:** `pip install -r Requirements.txt`
3. **Download HKH dataset:** Run download script
4. **Start Week 1, Day 1:** EDA and dataset preparation
5. **Daily standups:** Track progress against milestones

**Expected Timeline:** 12 days from start to submission-ready  
**Confidence Level:** 85% for MCC ‚â• 0.88 (based on evidence)

---

**This is the blueprint. Execute methodically. Track everything. Trust the process.**

*MCC 0.04 ‚Üí 0.88 is achievable. Let's build.*
